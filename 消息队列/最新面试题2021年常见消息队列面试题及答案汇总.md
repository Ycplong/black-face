# 最新面试题2021年常见消息队列面试题及答案汇总

### 全部面试题答案，更新日期：01月30日，直接下载吧！

### 下载链接：[高清500+份面试题资料及电子书，累计 10000+ 页大厂面试题  PDF](/docs/index.md)

## 消息队列

### 题1：[RabbitMQ 有哪些重要组件？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题1rabbitmq-有哪些重要组件)<br/>
ConnectionFactory(连接管理器)：应用程序与RabbitMQ之间建立连接的管理器

Channel(信道)：消息推送使用的通道

Exchange(交换器)：用于接受、分配消息

Queue(队列)：用于存储生产者的消息

RoutingKey(路由键)：用于把生产者的数据分配到交换器上

BindKey(绑定键)：用于把交换器的消息绑定到队列上

### 题2：[如何保证 RabbitMQ 消息队列的高可用？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题2如何保证-rabbitmq-消息队列的高可用)<br/>
RabbitMQ有三种模式：单机模式，普通集群模式，镜像集群模式。

单机模式：就是demo级别的，一般是指本地启动MQ，目前几乎没有公司生产中用单机模式。

普通集群模式：意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。

镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，用户创建的queue，无论元数据（元数据指RabbitMQ的配置数据）还是queue的消息都会存在于多个实例上，然后每次用户写消息到queue时都会自动把消息发送到多个实例的queue中进行消息同步。

### 题3：[Kafka 能否脱离 Zookeeper 单独使用吗？为什么？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题3kafka-能否脱离-zookeeper-单独使用吗为什么)<br/>
kafka不能脱离zookeeper单独使用，因为kafka使用zookeeper管理和协调kafka的节点服务器。

### 题4：[数据传输的事务定义有哪三种？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题4数据传输的事务定义有哪三种)<br/>
和 MQTT 的事务定义一样都是3种。

1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输。

2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输。

3）精确的一次（Exactly once）: 不会漏传输也不会重复传输，每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的。

### 题5：[Kafka 中如何减少 ISR 扰动？broker何时离开 ISR？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题5kafka-中如何减少-isr-扰动broker何时离开-isr)<br/>
ISR是一组与leaders完全同步的消息副本，也就是说ISR中包含了所有提交的消息。

ISR应该总是包含所有的副本，直到出现真正的故障。

如果一个副本从leader中脱离出来，将会从ISR中删除。

### 题6：[Kafka 中使用零拷贝（Zero Copy）有哪些场景？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题6kafka-中使用零拷贝zero-copy有哪些场景)<br/>
Kafka中体现零拷贝使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。

**基于mmap的索引**

索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态 的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap 虽然避免了不必要的 拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap 的创建和销毁成本可 能是不一样的。很高的创建和销毁开销会抵消 零拷贝 带来的性能优势。由于这种不确 定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。

**日志文件读写所用的TransportLayer**

TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了零拷贝。对Kafka而言，如果I/O通道使用普通的PLAINTEXT，那么，Kafka就可以利用零拷贝特性，直接将页缓存中的数据发送到网卡的 Buffer 中，避免中间的多次拷贝。相反，如果I/O通道启用了SSL，那么，Kafka便无法利用零拷贝特性了。


### 题7：[RabbitMQ 实现消息持久化需要满足哪些条件？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题7rabbitmq-实现消息持久化需要满足哪些条件)<br/>
RabbitMQ 要实现消息持久化，必须满足以下 4 个条件：

1、投递消息的时候durable设置为true，消息持久化，代码：channel.queueDeclare(x, true, false, false, null)，第2个参数设置为true持久化；

2、设置投递模式deliveryMode设置为2（持久），代码：channel.basicPublish(x, x, MessageProperties.PERSISTENTTEXTPLAIN,x)，第3个参数设置为存储纯文本到磁盘；

3、消息已经到达持久化交换器上；

4、消息已经到达持久化的队列。

### 题8：[Kafka 中如何获取 topic 主题的列表？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题8kafka-中如何获取-topic-主题的列表)<br/>
获取topic主题的列表命令：

```shell
bin/kafka-topics.sh --list --zookeeper localhost:2181
```

### 题9：[Kafka 中能否手动删除消息吗？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题9kafka-中能否手动删除消息吗)<br/>
Kafka不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。当然，它是支持手动删除消息的。

对于设置了Key且参数cleanup.policy=compact的主题而言，可以构造一条<Key，null>的消息发送给Broker，依靠Log Cleaner组件提供的功能删除掉该Key的消息。

对于普通主题而言，可以使用kafka-delete-records命令，或编写程序调用Admin.deleteRecords方法来删除消息。

这两种方法殊途同归，底层都是调用Admin的deleteRecords方法，通过将分区Log Start Offset值抬高的方式间接删除消息。

### 题10：[Kafka 中如何提高远程用户的吞吐量？](/docs/消息队列/最新面试题2021年常见消息队列面试题及答案汇总.md#题10kafka-中如何提高远程用户的吞吐量)<br/>
如果用户位于与broker不同的数据中心，则可能需要调优套接口缓冲区大小，以对长网络延迟进行摊销。


### 题11：rabbitmq-中消息基于什么传输<br/>


### 题12：说说-kafka-维护消费状态跟踪的方法<br/>


### 题13：kafka-如何设置接收的消息大小<br/>


### 题14：rabbitmq-中-broker-和-cluster-分别是指什么<br/>


### 题15：kafka分布式的情况下如何保证消息的顺序消费<br/>


### 题16：kafka-消费者如何不自动提交偏移量由应用提交<br/>


### 题17：rabbitmq-接收到消息后必须消费吗<br/>


### 题18：rabbitmq-如何保证消息顺序性<br/>


### 题19：如何避免消息重复投递或重复消费<br/>


### 题20：rabbitmq-有哪些重要角色<br/>


### 题21：amqp是什么<br/>


### 题22：kafka-中位移-offset-有什么作用<br/>


### 题23：rabbitmq-如何确保每个消息能被消费<br/>


### 题24：为什么使用消息队列<br/>


### 题25：kafka-是如何保证数据不丢失的<br/>


![大厂面试题](../../imgs/pages.jpg "Java精选")

![大厂面试题](../../imgs/pdfs.png "Java精选")

![大厂面试题](../../imgs/weixin.png "Java精选")